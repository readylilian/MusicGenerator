{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fluidsynth\n",
    "import magenta\n",
    "import magenta.music as mm\n",
    "from magenta.common import merge_hparams\n",
    "from magenta.contrib import training as contrib_training\n",
    "from magenta.models.music_vae import data\n",
    "from magenta.models.music_vae import data_hierarchical\n",
    "from magenta.models.music_vae import lstm_models\n",
    "from magenta.models.music_vae.base_model import MusicVAE\n",
    "from magenta.models.music_vae.trained_model import TrainedModel\n",
    "from magenta.models.music_vae import configs\n",
    "import note_seq\n",
    "import tensorflow\n",
    "import glob\n",
    "import collections\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## hparams is hyperparameters, increasing free_bits\n",
    "## and decreasing max_deta creates better replicas but worse random samples\n",
    "HParams = contrib_training.HParams\n",
    "\n",
    "## sets up the config class later used to train the model\n",
    "class Config(collections.namedtuple(\n",
    "    'Config',\n",
    "    ['model', 'hparams', 'note_sequence_augmenter',\n",
    "    'data_converter', 'train_examples_path', 'eval_examples_path',\n",
    "     'tfds_name'])):\n",
    "    def values(self):\n",
    "        return self._asdict()\n",
    "\n",
    "## sets everything in config to default values\n",
    "Config.__new__.__defaults__=(None,) * len(Config._fields)\n",
    "\n",
    "## allows the config class to update itself\n",
    "def update_config(config, update_dict):\n",
    "  config_dict = config.values()\n",
    "  config_dict.update(update_dict)\n",
    "  return Config(**config_dict)\n",
    "\n",
    "CONFIG_MAP = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\musicgenerator\\venv\\lib\\site-packages\\pretty_midi\\pretty_midi.py:101: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "midi1_set = glob.glob(\"./MidiSet1/*.mid\")\n",
    "midi2_set = glob.glob(\"./MidiSet2/*.mid\")\n",
    "midi3_set = glob.glob(\"./MidiSet3/*.mid\")\n",
    "note1_set = []\n",
    "note2_set = []\n",
    "note3_set = []\n",
    "# imports 3 sets of songs from the files in the project\n",
    "# converts these midi files to note sequences and stores in a list\n",
    "def import_songs():\n",
    "    from note_seq.protobuf import music_pb2\n",
    "    count = 0\n",
    "\n",
    "    for x in midi1_set:\n",
    "        sequence = note_seq.midi_file_to_note_sequence(midi1_set[count])\n",
    "        note1_set.append(sequence)\n",
    "        # note_seq.play_sequence(sequence, synth=note_seq.synthesize)\n",
    "        count += 1\n",
    "    count = 0\n",
    "    for x in midi2_set:\n",
    "        sequence = note_seq.midi_file_to_note_sequence(midi2_set[count])\n",
    "        note2_set.append(sequence)\n",
    "        # note_seq.play_sequence(sequence, synth=note_seq.synthesize)\n",
    "        count += 1\n",
    "    count = 0\n",
    "    for x in midi3_set:\n",
    "        sequence = note_seq.midi_file_to_note_sequence(midi3_set[count])\n",
    "        note3_set.append(sequence)\n",
    "        # note_seq.play_sequence(sequence, synth=note_seq.synthesize)\n",
    "        count += 1\n",
    "import_songs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initializes a 16 bar trio model to train\n",
    "trio_16bar_converter = data.TrioConverter(\n",
    "    steps_per_quarter=4,\n",
    "    slice_bars=16,\n",
    "    gap_bars=2)\n",
    "## simplest version of the 16 bar trio because it has the best generation\n",
    "## while still being something I understand\n",
    "CONFIG_MAP['hierdec-trio_16bar'] = Config(\n",
    "    model=MusicVAE(\n",
    "        lstm_models.BidirectionalLstmEncoder(),\n",
    "        lstm_models.HierarchicalLstmDecoder(\n",
    "            lstm_models.SplitMultiOutLstmDecoder(\n",
    "                core_decoders=[\n",
    "                    lstm_models.CategoricalLstmDecoder(),\n",
    "                    lstm_models.CategoricalLstmDecoder(),\n",
    "                    lstm_models.CategoricalLstmDecoder()],\n",
    "                output_depths=[\n",
    "                    90,  # melody\n",
    "                    90,  # bass\n",
    "                    512,  # drums\n",
    "                ]),\n",
    "            level_lengths=[16, 16],\n",
    "            disable_autoregression=True)),\n",
    "    hparams=merge_hparams(\n",
    "        lstm_models.get_default_hparams(),\n",
    "        HParams(\n",
    "            batch_size=256,\n",
    "            max_seq_len=256,\n",
    "            z_size=512,\n",
    "            enc_rnn_size=[2048, 2048],\n",
    "            dec_rnn_size=[1024, 1024],\n",
    "            free_bits=256,\n",
    "            max_beta=0.2,\n",
    "        )),\n",
    "    note_sequence_augmenter=None,\n",
    "    data_converter=trio_16bar_converter,\n",
    "    train_examples_path=None,\n",
    "    eval_examples_path=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building MusicVAE model with BidirectionalLstmEncoder, HierarchicalLstmDecoder, and hparams:\n",
      "{'max_seq_len': 256, 'z_size': 512, 'free_bits': 256, 'max_beta': 0.2, 'beta_rate': 0.0, 'batch_size': 4, 'grad_clip': 1.0, 'clip_mode': 'global_norm', 'grad_norm_clip_to_zero': 10000, 'learning_rate': 0.001, 'decay_rate': 0.9999, 'min_learning_rate': 1e-05, 'conditional': True, 'dec_rnn_size': [1024, 1024], 'enc_rnn_size': [2048, 2048], 'dropout_keep_prob': 1.0, 'sampling_schedule': 'constant', 'sampling_rate': 0.0, 'use_cudnn': False, 'residual_encoder': False, 'residual_decoder': False, 'control_preprocessing_rnn_size': [256]}\n",
      "INFO:tensorflow:\n",
      "Encoder Cells (bidirectional):\n",
      "  units: [2048, 2048]\n",
      "\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "INFO:tensorflow:\n",
      "Hierarchical Decoder:\n",
      "  input length: 256\n",
      "  level output lengths: [16, 16]\n",
      "\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "INFO:tensorflow:\n",
      "Decoder Cells:\n",
      "  units: [1024, 1024]\n",
      "\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "INFO:tensorflow:\n",
      "Decoder Cells:\n",
      "  units: [1024, 1024]\n",
      "\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "INFO:tensorflow:\n",
      "Decoder Cells:\n",
      "  units: [1024, 1024]\n",
      "\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From d:\\pycharmprojects\\musicgenerator\\venv\\lib\\site-packages\\magenta\\models\\music_vae\\base_model.py:189: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From d:\\pycharmprojects\\musicgenerator\\venv\\lib\\site-packages\\magenta\\contrib\\rnn.py:474: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From d:\\pycharmprojects\\musicgenerator\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py:447: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From d:\\pycharmprojects\\musicgenerator\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\linalg\\linear_operator_diag.py:175: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Do not pass `graph_parents`.  They will  no longer be used.\n",
      "WARNING:tensorflow:From d:\\pycharmprojects\\musicgenerator\\venv\\lib\\site-packages\\tensorflow_probability\\python\\bijectors\\affine_linear_operator.py:116: LinearOperator.graph_parents (from tensorflow.python.ops.linalg.linear_operator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Do not call `graph_parents`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pycharmprojects\\musicgenerator\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\legacy_tf_layers\\core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  warnings.warn('`tf.layers.dense` is deprecated and '\n",
      "d:\\pycharmprojects\\musicgenerator\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "d:\\pycharmprojects\\musicgenerator\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The passed save_path is not a valid checkpoint: /checkpoints/hierdec-trio_16bar.ckpt",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-7-ed8585f21b17>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[0mconfigs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mCONFIG_MAP\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'hierdec-trio_16bar'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m \u001B[1;36m4\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m     \u001B[0mcheckpoint_dir_or_path\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'/checkpoints/hierdec-trio_16bar.ckpt'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      7\u001B[0m )\n\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\pycharmprojects\\musicgenerator\\venv\\lib\\site-packages\\magenta\\models\\music_vae\\trained_model.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, config, batch_size, checkpoint_dir_or_path, var_name_substitutions, session_target, **sample_kwargs)\u001B[0m\n\u001B[0;32m    132\u001B[0m           \u001B[0msaver\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrestore\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sess\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcheckpoint_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    133\u001B[0m       \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 134\u001B[1;33m         \u001B[0msaver\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrestore\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sess\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcheckpoint_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    135\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    136\u001B[0m   def sample(self, n=None, length=None, temperature=1.0, same_z=False,\n",
      "\u001B[1;32md:\\pycharmprojects\\musicgenerator\\venv\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001B[0m in \u001B[0;36mrestore\u001B[1;34m(self, sess, save_path)\u001B[0m\n\u001B[0;32m   1288\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mcheckpoint_management\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcheckpoint_exists_internal\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcheckpoint_prefix\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1289\u001B[0m       raise ValueError(\"The passed save_path is not a valid checkpoint: \" +\n\u001B[1;32m-> 1290\u001B[1;33m                        checkpoint_prefix)\n\u001B[0m\u001B[0;32m   1291\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1292\u001B[0m     \u001B[0mlogging\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Restoring parameters from %s\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcheckpoint_prefix\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: The passed save_path is not a valid checkpoint: /checkpoints/hierdec-trio_16bar.ckpt"
     ]
    }
   ],
   "source": [
    "def interpolate(model, start_seq, end_seq, num_steps, max_length=32,\n",
    "                assert_same_length=True, temperature=0.5,\n",
    "                individual_duration=4.0):\n",
    "  \"\"\"Interpolates between a start and end sequence.\"\"\"\n",
    "  note_sequences = model.interpolate(\n",
    "      start_seq, end_seq,num_steps=num_steps, length=max_length,\n",
    "      temperature=temperature,\n",
    "      assert_same_length=assert_same_length)\n",
    "\n",
    "  print('Interpolation')\n",
    "  interp_seq = mm.sequences_lib.concatenate_sequences(\n",
    "      note_sequences, [individual_duration] * len(note_sequences))\n",
    "\n",
    "  return interp_seq if num_steps > 3 else note_sequences[num_steps // 2]\n",
    "\n",
    "def download(note_sequence, filename):\n",
    "  mm.sequence_proto_to_midi_file(note_sequence, filename)\n",
    "  download(filename)\n",
    "\n",
    "print('Done')\n",
    "#hierdec_trio_16bar_config = CONFIG_MAP['hierdec-trio_16bar']\n",
    "\n",
    "#music_vae = TrainedModel(\n",
    "    #configs.CONFIG_MAP['hierdec-trio_16bar'],\n",
    "   # batch_size= 4,\n",
    "    #checkpoint_dir_or_path='/checkpoints/hierdec-trio_16bar.ckpt'\n",
    "#)\n",
    "\n",
    "#music_vae_train \\\n",
    "#--config=flat-trio_16bar \\\n",
    "#--run_dir=/tmp/music_vae/ \\\n",
    "#--mode=train \\\n",
    "#--examples_path = MidiSet1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running...\n",
      "0\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "##Generates samples based off the trained model's checkpoint\n",
    "config = 'hierdec-mel_16bar'\n",
    "checkpoint = 'hierdec-mel_16bar.tar'\n",
    "mode = 'sample'\n",
    "num_output = 5\n",
    "output = 'generated'\n",
    "\n",
    "cmd = f'music_vae_generate --config={config} --checkpoint_file={checkpoint} ' \\\n",
    "      f'--mode={mode} --num_outputs={num_output} --output_dir={output}'\n",
    "\n",
    "print('Running...')\n",
    "print(os.system(cmd))\n",
    "print('Done')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running...\n",
      "1\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "##Interpolates between provided samples\n",
    "mode = 'interpolate'\n",
    "num_output = 5\n",
    "inone = 'MidiSet2/Test1.mid'\n",
    "intwo = 'MidiSet2/Test2.mid'\n",
    "\n",
    "cmd = f'music_vae_generate --config{config} --checkpoint_file={checkpoint}' \\\n",
    "    f'--mode={mode} --num_outputs={num_output} --input_midi_1={inone} --input_midi_2={intwo}' \\\n",
    "    f'--output_dir={output}'\n",
    "\n",
    "#music_vae_generate --config=hierdec-mel_16bar --checkpoint_file=hierdec-mel_16bar.tar --mode=interpolate --num_outputs=1 --input_midi_1=MidiSet2/Test1.mid --input_midi_2=MidiSet2/Test2.mid --output_dir=generated\n",
    "\n",
    "print('Running...')\n",
    "print(os.system(cmd))\n",
    "print('Done')\n",
    "#interp_seq=note_seq.sequences_lib.concatenate_sequences(note_seq)\n",
    "#note_seq.play_sequence(interp_seq, synth=note_seq.fluidsynth)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}